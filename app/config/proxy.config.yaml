# Organization-specific LiteLLM Proxy config

model_list:
  # Example: route all openai/* to a single key
  - model_name: "openai/*"
    litellm_params:
      model: "openai/*"
      api_key: os.environ/OPENAI_API_KEY

  # Example Azure mapping
  - model_name: "gpt-4o"
    litellm_params:
      model: "azure/gpt-4o"
      api_key: os.environ/AZURE_API_KEY
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION

  # Example Anthropic
  - model_name: "claude-3.5-sonnet"
    litellm_params:
      model: "anthropic/claude-3-5-sonnet"
      api_key: os.environ/ANTHROPIC_API_KEY

litellm_settings:
  telemetry: false
  request_timeout: 600
  num_retries: 5
  drop_params: true

router_settings:
  routing_strategy: usage-based-routing-v2
  # redis_host: os.environ/REDIS_HOST
  # redis_password: os.environ/REDIS_PASSWORD
  # redis_port: os.environ/REDIS_PORT

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  store_model_in_db: true  # enable adding models at runtime via UI/API
  # database_url: os.environ/DATABASE_URL  # if you want to override env

# Optional pass-through example
# general_settings:
#   pass_through_endpoints:
#     - path: "/v1/rerank"
#       target: "https://api.cohere.com/v1/rerank"
#       headers:
#         content-type: application/json
#         accept: application/json
#       forward_headers: true
